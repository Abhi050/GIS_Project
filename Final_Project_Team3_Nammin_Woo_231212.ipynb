{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project (Team3)\n",
    "\n",
    "This project aims to figure out unique patterns of crime incidents in Washington DC by visualizing spatial representations on a map and analyzing geographical attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Ⅰ. [WEB] Download Raw data \n",
    "\n",
    "- All datasets were gathered from [Open Data DC](https://opendata.dc.gov/explore?collection=Dataset) and preprocessed. \n",
    "\n",
    "- There are THREE types of specific datasets that were used in this project\n",
    "1. CRIME INCIDENTS (5 years: ‘19~23): *.Shp, *CSV\n",
    "2. Properties(13: Schools, Gas station, etc.): *.Shp\n",
    "3. Census Economic Characteristics(78 Statistics): *.Shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Ⅱ. [ArcPro] Make Initial GDB- 'MyProject_pre.gdb'\n",
    "\n",
    "  - Batch Import (or add feature) *.shp files\n",
    "  - Show Featrues in the Map, Edit Point Symbology \n",
    "  - Arcpy: SET GDB Environment, Make KDE, etc <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Verify GDB \n",
    "\n",
    "**Below code is to verify GDB which was generated on ArcPro**\n",
    "`arcpy.env.workspace` was set to the path for `MyProject_pre.gdb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'.\\MyProject_pre.gdb'  \n",
    "arcpy.env.workspace = (path)\n",
    "arcpy.overwriteOutput = True\n",
    "#\\\\apporto.com\\dfs\\GWU\\Users\\nanminwoo_gwu\\Desktop\\IGSUP_data_student\\IGSUP_data_student\\@Final Project\\MyProject (GDB,ArcPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Crime_Incidents_in_2023_kml_point', 'Crime_Incidents_in_2023_shp', 'Census_Economic_shp', 'Census_Economic_kml_Polygons', 'Bank_Locations', 'Farmers_Market_Locations', 'Gas_Stations', 'Grocery_Store_Locations', 'Hospitals', 'Hotels', 'Liquor_Licenses', 'Metro_Station_Entrances_in_DC', 'National_Parks', 'Roads', 'Shopping_Centers', 'Sidewalk_Cafe', 'Crime_Incidents_in_2022', 'Crime_Incidents_in_2021', 'Crime_Incidents_in_2020', 'Crime_Incidents_in_2019', 'DC_Public_Schools', 'Crime_Incidents_19_23_Merged', 'Crime_Incidents_19_23_Merged_CSV']\n"
     ]
    }
   ],
   "source": [
    "# Check Feature classes\n",
    "fc_list = arcpy.ListFeatureClasses()\n",
    "print(fc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Census_Economic Feature class\n",
    "  \n",
    "   - Basic Check: descrie, field, row counts, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc2 = arcpy.Describe(\"Census_Economic_shp\")\n",
    "desc2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fld in desc2.fields:\n",
    "    #    print(\"\\t\" + fld.name)\n",
    "    print(f\"{fld.name} : {fld.Type}\")\n",
    "\n",
    "# Number of record: GetCount : 206 Census Track Areas\n",
    "count = arcpy.GetCount_management('Census_Economic_shp')\n",
    "print(f\"Name: Census_Econmic_variales, feature count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Census_Economic (2020 version)\n",
    "desc2 = arcpy.Describe(\"Census_Economic_shp\")\n",
    "desc2 \n",
    "for fld in desc2.fields:\n",
    "    #    print(\"\\t\" + fld.name)\n",
    "    print(f\"{fld.name} : {fld.Type}\")\n",
    "# Number of record: GetCount : 206 Census Track Areas\n",
    "count = arcpy.GetCount_management('Census_Economic_shp')\n",
    "print(f\"Name: Census_Econmic_variales, feature count: {count}\")\n",
    "# Check the sample: DP03_0009PE (truncated:DP03_0009P): unemployment_rate, DP03_0119PE(DP03_0119P): pct_all_families_below_poverty\n",
    "from arcpy.da import *\n",
    "with arcpy.da.SearchCursor(\"Census_Economic_shp\",(\"DP03_0009P\", \"DP03_0119P\")) as cursor:\n",
    "    i= 0\n",
    "    for val in cursor: \n",
    "            while i < 5:\n",
    "                print(f'Unemployment(%): {val[0]}')\n",
    "                print(f'Poverty(%): {val[1]}')\n",
    "                i += 1   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Ⅲ. Generate New Features\n",
    "\n",
    " - To enrich attributes of crime incidents, a feature engineering was performed as follows. \n",
    " - In this stage, CRIME INCIDENTS.CSV (Same data but *.CSV format) was additionally used. (Because Timestamp variables were truncked in *.Shp)\n",
    " - Six features were generated as below.\n",
    " - **The subsequent analysis will rely on an aggregated data frame, specifically a feature class within the GDB, encompassing five years' worth of crime incidents.**  \n",
    "  \n",
    "> *1. Crime_Type: Recategorized as 4 types* \n",
    ">   *(Theft, Other_Property_Crimes, Robbery, Other_Violent_Crimes)* \n",
    "> \n",
    "> *2. Clear_Time: Time to clear a crime incident(Minutes)*\n",
    ">   *(END_DATE - START_DATE)*\n",
    "> \n",
    "> *3. Pandemic Phase: 3 Phases*\n",
    ">   *(Before: 2019.1~2020.2, Lockdown: 2020.3.~ 2021.7, Post: 2021.8~2323.12)* \n",
    "> \n",
    "> *4. Season: Spring,Summer,Fall,Winter*\n",
    "> \n",
    "> *5. Date Phase: 1: 'Beginning', 2: 'Middle', 3: 'End'*\n",
    "> \n",
    "> *6. Time hour: 0~23*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Crime_Incidents_in_2019: (33950, 26)\n",
      "Shape of Crime_Incidents_in_2020: (27917, 26)\n",
      "Shape of Crime_Incidents_in_2021: (28348, 26)\n",
      "Shape of Crime_Incidents_in_2022: (27211, 26)\n",
      "Shape of Crime_Incidents_in_2023: (26022, 26)\n"
     ]
    }
   ],
   "source": [
    "# Read CRIME INCIDENTS (*.CSV) dataset from 2019~2023\n",
    "path = r'.\\Data_update\\Crime Raw data(openDC)_CSV'  \n",
    "import pandas as pd\n",
    "import os\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.csv'):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        df_name = filename.split('.')[0]\n",
    "        year = df_name[-4:]\n",
    "        globals()[df_name]= pd.read_csv(filepath)\n",
    "        globals()[df_name]['Year'] = year # Add year column to distinguish\n",
    "        print(f'Shape of {df_name}: {globals()[df_name].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143448, 26)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge 5 years\n",
    "# List of dataframes\n",
    "dfs = [Crime_Incidents_in_2019, Crime_Incidents_in_2020, Crime_Incidents_in_2021, Crime_Incidents_in_2022, Crime_Incidents_in_2023]\n",
    "Crime_Incidents_19_23 = pd.concat(dfs, ignore_index=True)\n",
    "Crime_Incidents_19_23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143448 143384\n"
     ]
    }
   ],
   "source": [
    "# Verify PK of dataset\n",
    "pk = ['CCN']  #PK is OBJECTID but it change whenever download it \n",
    "temp = Crime_Incidents_19_23.drop_duplicates(subset=pk)\n",
    "print(f'# of records Before Clean: {Crime_Incidents_19_23.shape[0]}\\n After Clean: {temp.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df = copy.deepcopy(temp) # will use CCN dup dropped \n",
    "\n",
    "# 1. Crime_Type:  4 types (Theft, Other_Property_Crimes, Robbery, Other_Violent_Crimes)  \n",
    "df['Crime_Type'] = df['OFFENSE']\n",
    "df['Crime_Type'] = df['Crime_Type'].replace(['THEFT F/AUTO', 'THEFT/OTHER'], 'Theft')\n",
    "df['Crime_Type'] = df['Crime_Type'].replace(['Arson', 'Burglary', 'Motor Vehicle Theft'], 'Other_Property_Crimes')\n",
    "df['Crime_Type'] = df['Crime_Type'].replace(['Robbery'], 'Robbery')\n",
    "df['Crime_Type'] = df['Crime_Type'].replace(['Assault with a Dangerous Weapon', 'Homicide', 'Sex Abuse'], 'Other_Violent_Crimes')\n",
    "\n",
    "# 2. Clear_Time: END_DATE - START_DATE(Minutes), Time to clear a crime incident\n",
    "df['START_DATE'] = pd.to_datetime(df['START_DATE'])\n",
    "df['END_DATE'] = pd.to_datetime(df['END_DATE'])\n",
    "df['Clear_Time'] = round((df['END_DATE'] - df['START_DATE']).dt.total_seconds() / 60,1)\n",
    "\n",
    "# 3. Pandemic Phase: (Before: 2019.1~2020.2, Lockdown: 2020.3.~ 2021.7, Post: 2021.8~2323.12) \n",
    "df['REPORT_DAT'] = pd.to_datetime(df['REPORT_DAT'])\n",
    "df['Pandemic_Phase'] = pd.cut(df['REPORT_DAT'],\n",
    "                               bins=[pd.Timestamp('2019-01-01'), pd.Timestamp('2020-03-01')\n",
    "                                     , pd.Timestamp('2021-08-01'), pd.Timestamp('2024-01-01')],\n",
    "                               labels=['Before', 'Lockdown', 'Post'])\n",
    "\n",
    "# 4. Season: Spring,Summer,Fall,Winter\n",
    "df['Season'] = df['REPORT_DAT'].dt.month % 12 // 3 + 1\n",
    "df['Season'] = df['Season'].map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'})\n",
    "\n",
    "# 5. Date Phase: 1: 'Beginning', 2: 'Middle', 3: 'End'\n",
    "df['Date_Phase'] = df['REPORT_DAT'].dt.day // 10 + 1\n",
    "df['Date_Phase'] = df['Date_Phase'].map({1: 'Beginning', 2: 'Middle', 3: 'End'})\n",
    "\n",
    "# 6. Time hour: 0~23\n",
    "df['Time_Hour'] = df['START_DATE'].dt.hour\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Export dataframe to CSV \n",
    "\n",
    "   * Exported CSV file will be added on the current GDB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Crime_Incidents_19_23.shape, df.shape)\n",
    "#\n",
    "feat = ['CCN','Year', 'Crime_Type', 'Clear_Time', 'Pandemic_Phase', 'Season', 'Date_Phase', 'Time_Hour'] \n",
    "# PK+ add features: \n",
    "df.to_csv(os.path.join(os.getcwd(),'Crime_Incidents_19_23_add_feat_all.csv'))\n",
    "#df[feat].to_csv(os.path.join(os.getcwd(),'Crime_Incidents_19_23_add_feat.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Ⅳ. [ArcPro] Make Final GDB - 'MyProject.gdb'\n",
    "\n",
    "  - Updated new features by adding generated output(Part Ⅲ CSV) to GDB\n",
    "  - Also Merged previous 5 year Crime incidents features(based on Shapefiles) into 1 feature\n",
    "  - Verified the final GDB\n",
    "  - *Feature class \"Crime_Incidents_19_23_Merged_CSV\" will be mainly used in upcoming analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Merging and Import part was commented out because final GDB was already generated when submission*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Aggregate current features based on Shapefiles \n",
    "# List of Crime shapefiles in current GDB\n",
    "feature_classes = ['Crime_Incidents_in_2019', 'Crime_Incidents_in_2020', 'Crime_Incidents_in_2021', 'Crime_Incidents_in_2022', 'Crime_Incidents_in_2023_shp']  #2023: test(kml,shp,etc)\n",
    "\n",
    "# [Finished] Define Output merged feature class \n",
    "# out_feature_class = \"Crime_Incidents_19_23_Merged\"\n",
    "# Used the Merge tool to merge 5 years features (But in memory, Should do Copy to save)\n",
    "# arcpy.Merge_management(feature_classes, out_feature_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a result, Field names\n",
    "desc = arcpy.Describe(\"Crime_Incidents_19_23_Merged\")\n",
    "for fld in desc.fields:\n",
    "    #    print(\"\\t\" + fld.name)\n",
    "    print(f\"{fld.name} : {fld.Type}\")\n",
    "print(df.columns.to_list())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Make \"Crime_Incidents_19_23_Merged_CSV\" by importing generated output(Part Ⅲ CSV)\n",
    "\n",
    "# [Finished] Import the CSV file as a table\n",
    "# arcpy.TableToTable_conversion(\"Crime_Incidents_19_23_add_feat_all.csv\", arcpy.env.workspace, \"crime_19_23_csv\")\n",
    "\n",
    "# [Worked on ArcPro] Converted the table to the Point feature class on ArcPro\n",
    "# 1. On the Map tab, in the Layer group, click the Add Data drop-down menu, and click XY Point Data.\n",
    "# 2. Choose a table that contains x,y coordinate data.\n",
    "# 3. Click the X Field drop-down arrow and click the field containing x-coordinate values.\n",
    "# 4. Click the Y Field drop-down arrow and click the field containing y-coordinate values.\n",
    "\n",
    "\n",
    "# Alternative trials by arcpy-- \n",
    "# arcpy.MakeTableView_management(in_csv, \"csv_view_2\")\n",
    "# arcpy.management.XYTableToPoint(\"csv_view_2\", \"Crime_Incidents_19_23_Merged_CSV\", \"X\", \"Y\")\n",
    "# arcpy.AddJoin_management(\"Crime_Incidents_19_23_Merged\", \"CCN\", \"csv_view_add_feat_f\", \"CCN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Ⅴ. Analysis \n",
    "   - (Interactive Work between ArcPy and ArcGIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "path = r'.\\MyProject.gdb'    # previous gdb (before update crime variables)\n",
    "arcpy.env.workspace = (path)\n",
    "arcpy.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Crime Incidents Pattern (KDE Hotspot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Basic Check: descrie, field, row counts, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"catalogPath\">catalogPath</td><td title=\"\\\\apporto.com\\dfs\\GWU\\Users\\nanminwoo_gwu\\Desktop\\IGSUP_data_student\\IGSUP_data_student\\@Final Project\\MyProject (GDB,ArcPy)\\MyProject.gdb\\Crime_Incidents_19_23_Merged_CSV\">\\\\apporto.com\\dfs\\GWU\\Users\\nanminwoo_gwu\\Desktop\\IGSUP_data_student\\IGSUP_data_student\\@Final Project\\MyProject (GDB,ArcPy)\\MyProject.gdb\\Crime_Incidents_19_23_Merged_CSV</td></tr><tr><td id = \"td0\" title=\"dataType\">dataType</td><td title=\"FeatureLayer\">FeatureLayer</td></tr></table><p class=\"gpresult\">For additional help,     see <a href=\"#\" onclick=\"chrome.webview.postMessage('describe_helpid_120003803');return false;\">arcpy.Describe</a></p><br>"
      ],
      "text/plain": [
       "<geoprocessing describe data object object at 0x0000025CAD7B0670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = arcpy.Describe(\"Crime_Incidents_19_23_Merged_CSV\")\n",
    "#desc = arcpy.Describe(\"Crime_Incidents_in_2023_kml_point\")\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID_1 : OID\n",
      "Shape : Geometry\n",
      "Field1 : Integer\n",
      "X : Double\n",
      "Y : Double\n",
      "CCN : Integer\n",
      "REPORT_DAT : String\n",
      "SHIFT : String\n",
      "METHOD : String\n",
      "OFFENSE : String\n",
      "BLOCK : String\n",
      "XBLOCK : Double\n",
      "YBLOCK : Double\n",
      "WARD : Double\n",
      "ANC : String\n",
      "DISTRICT : Double\n",
      "PSA : Double\n",
      "NEIGHBORHOOD_CLUSTER : String\n",
      "BLOCK_GROUP : String\n",
      "CENSUS_TRACT : Double\n",
      "VOTING_PRECINCT : String\n",
      "LATITUDE : Double\n",
      "LONGITUDE : Double\n",
      "BID : String\n",
      "START_DATE : String\n",
      "END_DATE : String\n",
      "OBJECTID : Integer\n",
      "OCTO_RECORD_ID : String\n",
      "Year : Integer\n",
      "Crime_Type : String\n",
      "Clear_Time : Double\n",
      "Pandemic_Phase : String\n",
      "Season : String\n",
      "Date_Phase : String\n",
      "Time_Hour : Double\n"
     ]
    }
   ],
   "source": [
    "for fld in desc.fields:\n",
    "    #    print(\"\\t\" + fld.name)\n",
    "    print(f\"{fld.name} : {fld.Type}\")\n",
    "\n",
    "# field_list = arcpy.ListFields(\"Crime_Incidents_in_2023_shp\")\n",
    "# field_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Crime incidents(5years), feature count: 143384\n"
     ]
    }
   ],
   "source": [
    "# Numer of record: GetCount\n",
    "count = arcpy.GetCount_management('Crime_Incidents_19_23_Merged_CSV')\n",
    "print(f\"Name: Crime incidents(5years), feature count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time stamp variales are truncated. So, they will be manually added after converting into Clearance_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: 2019-05-16 23:15:24+00:00\n",
      "END: 2019-05-16 23:18:13+00:00\n",
      "START: 2019-05-18 10:31:59+00:00\n",
      "END: 2019-05-18 11:04:48+00:00\n",
      "START: 2019-05-18 18:30:47+00:00\n",
      "END: 2019-05-18 18:35:33+00:00\n",
      "START: 2019-04-02 23:20:46+00:00\n",
      "END: None\n",
      "START: 2019-04-04 05:00:17+00:00\n",
      "END: 2019-04-04 05:50:06+00:00\n",
      "Reached 5 iterations. Do something else here.\n"
     ]
    }
   ],
   "source": [
    "# Check the sample\n",
    "from arcpy.da import *\n",
    "with arcpy.da.SearchCursor(\"Crime_Incidents_19_23_Merged_CSV\", (\"START_DATE\", \"END_DATE\")) as cursor:\n",
    "    i = 0\n",
    "    for val in cursor:\n",
    "        if i < 5:\n",
    "            print(f'START: {val[0]}')\n",
    "            print(f'END: {val[1]}')\n",
    "            i += 1\n",
    "        else:\n",
    "            # Add your desired action here when i reaches 5 or more\n",
    "            print(\"Reached 5 iterations. Do something else here.\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Create KDE feature \n",
    "\n",
    "- Interactive KDE Plot on ArcGIS by input value as parameter To EXPLORE pattern of Crime  \n",
    "- Two Input Parameters: Pandemic Phase, Crime Type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose Crime Type (1:Theft, 2:Other_Property_Crimes), 3:Robbery, 4:Other_Violent_Crimes1\n",
      "Theft\n"
     ]
    }
   ],
   "source": [
    "# 1. Inactive 'Crime_Incidents_19_23' points\n",
    "# 2. Delete 'Crime_Incidents_19_23' [temp layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcpy.sa import *\n",
    "arcpy.CheckOutExtension(\"Spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose Crime Type (1:Theft, 2:Other_Property_Crimes), 3:Robbery, 4:Other_Violent_Crimes4\n",
      "Other_Violent_Crimes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. ask user to chosse crime type  #Pandemic_Phase # Crime_Type\n",
    "list = {1:'Theft', 2:'Other_Property_Crimes', 3:'Robbery', 4:'Other_Violent_Crimes'}\n",
    "crime_type = input(\"Choose Crime Type (1:Theft, 2:Other_Property_Crimes), 3:Robbery, 4:Other_Violent_Crimes\")\n",
    "index = int(crime_type)\n",
    "crime_type = list[index]\n",
    "print(crime_type)\n",
    "\n",
    "out_layers = \"Crime_Incidents_19_23_\" + crime_type\n",
    "arcpy.MakeFeatureLayer_management(in_features=\"Crime_Incidents_19_23_Merged_CSV\"\n",
    "                                  , out_layer=out_layers)\n",
    "\n",
    "\n",
    "#2.\n",
    "new_field = arcpy.AddFieldDelimiters(arcpy.env.workspace, \"Crime_Type\")\n",
    "SQLExp = f\"{new_field} = '{crime_type}'\"  # Use quotes for string comparison\n",
    "\n",
    "try:\n",
    "    arcpy.SelectLayerByAttribute_management(in_layer_or_view=out_layers,\n",
    "                                            selection_type=\"NEW_SELECTION\",\n",
    "                                            where_clause=SQLExp)\n",
    "    \n",
    "    # 3. Make KDE feature by using temporary features\n",
    "\n",
    "    with arcpy.EnvManager(extent=arcpy.Extent(-77.112318, 38.814667, -76.910140, 38.993573)):\n",
    "        outKernelDensity2 = KernelDensity(in_features=out_layers,\n",
    "                                          population_field=\"\",\n",
    "                                          cell_size=0.005,\n",
    "                                          search_radius=0.01) \n",
    "\n",
    "    # 1. Inactive 'Crime_Incidents_19_23' points\n",
    "    # 2. Delete 'Crime_Incidents_19_23' [temp layer]\n",
    "    \n",
    "    # 4.Refresh selection\n",
    "#    arcpy.SelectLayerByAttribute_management(in_layer_or_view='Crime_Incidents_19_23',\n",
    "#                                            selection_type=\"CLEAR_SELECTION\")\n",
    "\n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TBD) 2. Explore Proximity feature\n",
    " \n",
    "  - Number of Property near crime spots\n",
    "  - Whether property exists Within a buffer area of each crime incident spot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a buffer around the crime incidents\n",
    "# arcpy.Buffer_analysis(\"Crime_incident\", \"Crime_Buffer\", \"100 Feet\")\n",
    "\n",
    "# # Intersect the buffer with the properties\n",
    "# arcpy.Intersect_analysis([\"Crime_Buffer\", \"Properties\"], \"Buffer_Properties\")\n",
    "\n",
    "# # Calculate the number of properties within each buffer\n",
    "# arcpy.Statistics_analysis(\"Buffer_Properties\", \"Buffer_Eat_drinking\", [[\"OBJECTID\", \"COUNT\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TBD Works (DEC 1 update: GDB, Code, ipynb,py.)\n",
    "# ex.  [Hospital] num_hospitals_crime: Integer or dummy(whether it exists or not, 0, 1)\t\t\t\t\t\t\t\n",
    "# 1. Calculate: 'num_hospitals' within 100 feet from a crime point \t\t\t\t\t\t\t\n",
    "# Hospital- Crime Point - SelectLayerByLocation WITHIN_A_DISTANCE (or Buffer_analysis)\t\t\t\t\t\t\t\n",
    "# GetCount(or Statistics_analysis)\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\n",
    "# 2. Iteration for all crime points: get spatial features\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\n",
    "# 3.  Link with socio-economic data  (summarized zonal statistics, crime intensity)\t\t\t\t\t\t\t\n",
    "# Summarize 'Average of num_hospitals' by Census_tract\t\t\t\t\t** Sum of\t\t\n",
    "# (End image)\t\t\t\t\t\t\t\n",
    "# Census\tPoverty\tnum_crime\tAvg_num_hospital\t\t\t\t\n",
    "# Region A\thigh\t10\t1\t\t\t\t\n",
    "\n",
    "\n",
    "# # Create a buffer around the crime incidents\n",
    "# arcpy.Buffer_analysis(\"Crime_incident\", \"Crime_Buffer\", \"100 Feet\")\n",
    "\n",
    "# # Intersect the buffer with the properties\n",
    "# arcpy.Intersect_analysis([\"Crime_Buffer\", \"Properties\"], \"Buffer_Properties\")\n",
    "\n",
    "# # Calculate the number of properties within each buffer\n",
    "# arcpy.Statistics_analysis(\"Buffer_Properties\", \"Buffer_Eat_drinking\", [[\"OBJECTID\", \"COUNT\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 4. Create Symbols- Numeric represent of Census variale on the Map (TBD)\n",
    "# # Join the economic characteristics to the census tracts\n",
    "# arcpy.JoinField_management(\"Census_Tracts\", \"TRACT_ID\", \"Economic_Characteristics\", \"TRACT_ID\", \"DP03_0009PE\")\n",
    "\n",
    "# # Classify the unemployment rate\n",
    "# arcpy.ApplySymbologyFromLayer_management(\"Census_Tracts\", \"Unemployment_Symbology.lyrx\")\n",
    "\n",
    "# Reference for opensource work\n",
    "# Read *gdb\n",
    "# import geopandas as gpd\n",
    "# # Read the .gdb file\n",
    "# gdf = gpd.read_file('project.gdb')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ef83ab4e3b1c610d58930f78968af47eb34a17cf26a42b6ce1eb23372798d71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
